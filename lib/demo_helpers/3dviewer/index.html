<!DOCTYPE html>
<html lang="en">

<head>
  <meta name="description" content="3D Visualizer for depth map predictions" />
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MuggledDPT</title>
</head>


<style>

  :root {
    --sidebar_width: min(30rem, 100vw);
    --playback_color: rgb(255, 0, 0);
    --bg_grad_start: rgb(70, 85, 80);
    --bg_grad_end: rgb(0,0,0);
    --bg_grad_recording: rgb(180, 70, 70);
  }

  * {
    color: white;
    font-family: monospace;
    text-align: center;
  }

  body {
    background: linear-gradient(var(--bg_grad_start), var(--bg_grad_end));
    margin: 0;
    padding: 0;
    width: 100vw;
    height: 100vh;
  }

  body.is_recording {
    background: linear-gradient(var(--bg_grad_recording), var(--bg_grad_end));
  }

  hr {
    border: none;
    width: 100%;
    height: 2rem;
    padding: 0;
    margin: 0;
  }

  #blocker_dialog {
    background-color: rgba(0,0,0,0.25);
    color: white;
    font-size: 1.5rem;
    font-weight: bold;
    border: none;
    outline: none;
    width: 100%;
    height: 100%;
  }

  #blocker_dialog_content {
    display: flex;
    justify-content: center;
    align-items: center;
    width: 100%;
    height: 100%;
  }

  #ctrl_sidebar {
    display: flex;
    flex-flow: column nowrap;
    /* 'safe' center avoids alignment problems when y-overflow occurs */
    justify-content: safe center;
    align-items: center;
    background-color: rgb(40,40,40, 0.5);
    box-sizing: border-box;
    padding: 2rem;
    margin: 0rem;
    gap: 1rem;
    user-select: none;
    position: fixed;
    left: 0;
    top: 0;
    height: 100vh;
    width: var(--sidebar_width);
    z-index: 5;
    overflow-y: auto;
  }

  #ctrl_sidebar.hidden_elem {
    /* Have to do this weirdly to enforce priority over default flex display! */
    display: none;
  }

  #display_area {
    display: grid;
    grid-template-rows: 1fr 80px;
    justify-content: center;
    align-items: center;
  }

  #canvas_3d {
    outline: solid 1px white;
    touch-action: none;
    cursor: move;
    margin: 0;
    padding: 0;
    position: fixed;
    top: 0;
    left: 0;
    width: 100vw;
    height: 100vh;
    z-index: 0;
    image-rendering: pixelated;
  }

  .drag_and_drop_indicator {
    background-color: rgba(255, 255, 255, 0.2);
  }

  #playback_slider {
    accent-color: var(--playback_color);
    width: 100%;
    padding: 0;
    margin: 0;
    z-index: 10;
  }

  #playpause_btn {
    background-color: var(--bg_grad_end);
    font-size: 1.5rem;
    padding: 0;
    margin: 0;
    min-width: 5ch;
    text-align: center;
    cursor: pointer;
    user-select: none;
  }

  #playpause_btn:hover {
    outline-color: white;
  }

  .sliderui_container {
    display: grid;
    grid-template-areas:
      "label output"
      "slider slider";
    grid-template-columns: auto 1fr;
    gap: 0.5rem;
    align-items: center;
    width: 100%;
    font-size: 1rem;
    padding: 0.5rem 0;
  }

  .sliderui_container > label {
    grid-area: label;
    text-align: left;
    font-weight: bold;
  }

  .sliderui_container > output {
    grid-area: output;
    text-align: right;
  }
  .sliderui_container > input[type="range"] {
    grid-area: slider;
    width: 100%;
    height: 4px;
  }

  #playback_container {
    display: flex;
    align-items: center;
    justify-content: center;
    gap: 1rem;
    box-sizing: border-box;
    padding: 1rem;
    position: fixed;
    bottom: 0;
    left: 50%;
    transform: translateX(-50%);
    width: 100%;
    color: white;
    z-index: 20;
    max-width: max(60vw, 150rem);
  }

  #playback_container.hidden_elem {
    /* Have to do this weirdly to enforce priority over default flex display! */
    display: none;
  }

  .toggleui_container {
    display: flex;
    flex-flow: row nowrap;
    justify-content: space-between;
    align-items: center;
    width: 100%;
    font-size: 1rem;
    padding: 0.5rem 0;
  }

  .toggleui_container > label {
    font-weight: bold;
  }

  .toggleui_btn {  
    --accent_color_from_js: rgb(200,200,200);
    display: flex;
    flex-flow: row nowrap;
    justify-content: start;
    align-items: center;
    height: 1rem;
    width: 100%;
    max-width: 4rem;
    min-width: 2rem;
    padding: 0.25rem;
    border-radius: 1rem;
    border: 2px solid black;
    cursor: pointer;
    background-color: hsl(0,0%,25%);
  }

  .toggleui_btn > input {
    display: none;
  }

  .toggleui_btn > div {
    background-color: rgb(210,210,210);
    width: 1rem;
    height: 100%;
    border-radius: 1rem;
    border: 1px solid black;
  }

  .toggleui_btn:has(:checked) {
    background-color: var(--accent_color_from_js);
    justify-content: end;
  }

  .regularui_button {
    background-color: var(--accent_color_from_js);
    border: 1px solid black;
    padding: 1rem 1.25rem;
    cursor: pointer;
    font-weight: bold;
    border-radius: 0.5rem;
  }

  .regularui_button:hover {
    border-color: white;
  }

  .header_row {
    display: flex;
    flex-flow: row;
    gap: 1rem;
    align-items: center;
    justify-content: center;
  }

  #info_btn {
    padding: 0.5rem 1rem;
  }

  #hide_btn, #unhide_btn {
    padding: 0.5rem 1rem;
    cursor: pointer;
    user-select: none;
    text-decoration: underline;
  }

  #unhide_btn {
    position: fixed;
    top: 0;
    left: 50%;
    transform: translateX(-50%);
    margin: 0.5rem;
    max-width: 16ch;
    z-index: 5;
  }

  .column_layout {
    display: flex;
    flex-flow: column nowrap;
  }

  .row_layout {
    display: flex;
    flex-flow: row nowrap;
  }

  .hidden_elem {
    display: none;
  }

</style>

<body>

  <dialog id="blocker_dialog">
    <div id="blocker_dialog_content"></div>
  </dialog>

  <div id="unhide_btn" class="hidden_elem">Show controls</div>

  <section id="ctrl_sidebar">
    <header class="header_row">
      <a id="info_btn" href="/info.html" target="_blank">info</a>
      <span>/</span>
      <div id="hide_btn">Hide</div>
    </header>
  </section>

  <!-- *** Main 3D plot *** -->
  <canvas id="canvas_3d"></canvas>

  <!-- Video playback control (hidden when visualizing images) -->
  <div id="playback_container" class="hidden_elem">
    <div id="playpause_btn" class="hidden_elem">
      <svg id="symbol_play" height="12" width="12" xmlns="http://www.w3.org/2000/svg">
        <polygon points="1,0 11,6 1,12" fill="white" />
      </svg>
      <svg id="symbol_pause" width="12" height="12" xmlns="http://www.w3.org/2000/svg" class="hidden_elem">
        <rect width="4" height="12" x="1" y="0" fill="white" />
        <rect width="4" height="12" x="7" y="0" fill="white" />
      </svg>
    </div>
    <input id="playback_slider" type="range" value="0" min="0" max="1" class="hidden_elem"/>
  </div>

  <!-- Hidden element, used for recording frame when saving is enabled -->
  <a id="save_frame_link" class="hidden_elem"></a>


<!-- Preload 'libraries' -->
<script src="ui.js"></script>
<script src="shaders.js"></script>
<script src="linalg.js"></script>
<script src="orbitcam.js"></script>
<script src="textures.js"></script>
<script src="mesh.js"></script>
<script src="gldata.js"></script>
<script src="save_gltf.js"></script>
<script src="save_obj.js"></script>


<!-- Main script for the page -->
<script>

  // -----------------------------------------------------------------------------------------------------------------
  // DOM Access

  const get_elem = (element_id) => document.getElementById(element_id);
  const DOM = {
    page: document.querySelector("body"),
    sidebar: get_elem("ctrl_sidebar"),
    hide_btn: get_elem("hide_btn"),
    unhide_btn: get_elem("unhide_btn"),
    canvas_3d : get_elem("canvas_3d"),
    playback_container: get_elem("playback_container"),
    playpause_btn: get_elem("playpause_btn"),
    playback_ctrl: get_elem("playback_slider"),
    save_frame_link: get_elem("save_frame_link"),
    symbol_play: get_elem("symbol_play"),
    symbol_pause: get_elem("symbol_pause"),
    blocker: get_elem("blocker_dialog"),
    blocker_content: get_elem("blocker_dialog_content"),
  };

  // CSS classes
  const GCSS = {
    hidden: "hidden_elem",
    is_recording: "is_recording",
    drag_and_drop: "drag_and_drop_indicator",
  };

  const CTX = {
    gl : DOM.canvas_3d.getContext("webgl2", {preserveDrawingBuffer: true}),
  };
  
  // Warn if webgl fails
  const bad_webgl = (CTX.gl === null);
  if (bad_webgl) {
    const error_msg = "Error setting up WebGL2. Cannot render data";
    alert(error_msg);
    console.log("Using canvas element:", DOM.canvas_3d);
    throw new Error(error_msg); 
  }

  
  // -----------------------------------------------------------------------------------------------------------------
  // Set up webgl data
  
  // Set up camera orbitting
  const ORBITCAM = new Orbit_Camera(initial_distance=5);
  ORBITCAM.bind_to_canvas(DOM.canvas_3d, render_3d);
  
  // Set up webgl rendering
  const GLDATA = new GLData(CTX.gl, SHADERDEFS);
  const TEXTUREDATA = new TextureData(CTX.gl, SHADERDEFS.textures);
  const MESHDATA = new MeshData(CTX.gl, SHADERDEFS.attrs);


  // -----------------------------------------------------------------------------------------------------------------
  // Global data
  
  // Holds info about the rendering canvas sizing (e.g. full-screen, in the browser)
  const DISPLAYINFO = {
    width: DOM.canvas_3d.clientWidth,
    height: DOM.canvas_3d.clientHeight,
    ar: DOM.canvas_3d.clientWidth / DOM.canvas_3d.clientHeight,
    res_scale: 0.75,
    draw_mode: WebGL2RenderingContext.POINTS,
  }

  // Holds info about the source of image & depth data
  const SOURCEINFO = {
    name: "unknown",
    is_static_image: true,
    is_video_file: false,
    is_webcam: false,
    is_metric_depth: false,
    total_frame_count: 1,
    max_frame_idx: 0,
  }

  // Holds information about how the server is encoding image & depth data
  const ENCODEINFO = {
    rgb: "image/jpg",
    depth: "image/png",
    size_header_rgb: "X-rgb-size",
    size_header_depth: "X-depth-size",
    header_frame_index: "X-frame-idx",
  }

  // Holds info about the RGB image sizing coming from the server
  const IMAGEINFO = {
    width: 100,
    height: 100,
    ar: 1.0,
  }

  // Holds info about the depth image sizing coming from the server
  // (generally this is different from the RGB image!)
  const DEPTHINFO = {
    width: 100,
    height: 100,
    ar: 1.0,
  }

  // Holds state for handling animations when working with video/webcam
  const ANIMSTATE = {
    idx: null,
    is_playing: false,
  }

  // Holds extra control state
  const CTRLS = {
    view_fov: 60.0,
    depth_limit: 100.0,
    scale_points_with_zoom: true,
    max_faces: 5_000_000,
    debug_line_render: false,
    wasd_sensitivity: 2.5,
    save_model_as_obj: false,
    save_model_depth: false,
    save_model_mask: false,
    save_model_image_as_jpeg: false,
  }

  // For saving frame data!
  const SAVECONFIG = {
    link_elem: DOM.save_frame_link,
    idx: 0,
    enable: false,
    rate: 5,
  }

  // Helpers for state-based behaviors
  let LAST_MASK_THRESHOLD = 0;
  let ASK_FOR_MASK_UPLOAD_CONFIRMATION = true;
  let DEFAULT_IS_UPLOADED_MASK = true;

  // For convenience
  const DEG2RAD = Math.PI / 180.0;
  const UICOLORS = [
    [30, 200, 190],
    [90, 210, 50],
    [255, 110, 0],
    [185, 0, 255],
    [45, 50, 200],
  ]


  // -----------------------------------------------------------------------------------------------------------------
  // Define UI

  const fov_ctrl = new SliderUI(DOM.sidebar, "FOV", 50.0, 0, 180);
  const tilt_ctrl = new SliderUI(DOM.sidebar, "Tilt", 0.0, -90.0, 90.0, step=0.1);
  const nplane_ctrl = make_01_slider(DOM.sidebar, "Near Plane", 0.0, 0.01);
  const zoff_ctrl = make_01_slider(DOM.sidebar, "Z-Offset", 0.05, 0.005);
  [fov_ctrl, tilt_ctrl, nplane_ctrl, zoff_ctrl].forEach(elem => elem.set_color(...UICOLORS[0]));
  append_spacer(DOM.sidebar);
  
  const dmax_ctrl = make_01_slider(DOM.sidebar, "Max Depth", 0.30, 0.001, min=0.001);
  const dmin_ctrl = make_01_slider(DOM.sidebar, "Min Depth (%)", 0.05, 0.001);
  [dmax_ctrl, dmin_ctrl].forEach(elem => elem.set_color(...UICOLORS[1]));
  append_spacer(DOM.sidebar);
  
  const density_ctrl = make_01_slider(DOM.sidebar, "Mesh Density", 0.5, 0.01);
  const jitter_ctrl = make_01_slider(DOM.sidebar, "Mesh Jitter", 1, 0.1);
  const maskthresh_ctrl = make_01_slider(DOM.sidebar, "Mask Threshold", 0, 0.001);
  [density_ctrl, jitter_ctrl, maskthresh_ctrl].forEach(elem => elem.set_color(...UICOLORS[2]));
  append_spacer(DOM.sidebar);
  
  const dispres_ctrl = make_01_slider(DOM.sidebar, "Display Resolution", DISPLAYINFO.res_scale, 0.05, min=0.05);
  const pointsize_ctrl = new SliderUI(DOM.sidebar, "Point Size", 12, 0.5, 50, 0.5);
  const ortho_toggle = new ToggleUI(DOM.sidebar, "Use Ortho Camera", false);
  const tri_toggle = new ToggleUI(DOM.sidebar, "Use Triangles", false);
  const depth_toggle = new ToggleUI(DOM.sidebar, "Use Depth Image", false);
  [dispres_ctrl, pointsize_ctrl, ortho_toggle, tri_toggle, depth_toggle].forEach(
    elem => elem.set_color(...UICOLORS[3])
  );
  append_spacer(DOM.sidebar);

  // Add button used to save mesh/texture data
  const saveobj_btn = new ButtonUI(DOM.sidebar, "Save 3D Model").set_color(...UICOLORS[4]);
  saveobj_btn.add_listener(() => {

    // Block interaction with screen while generating save data
    const file_type = CTRLS.save_model_as_obj ? ".obj" : ".glb";
    DOM.blocker_content.innerText = `...Creating ${file_type} file...`;
    DOM.blocker.showModal();
    setTimeout(async () => {

      const base_save_name = SOURCEINFO.name.split(".")[0];
      const curr_frame_idx = parseInt(DOM.playback_ctrl.value);
      const model_save_name = curr_frame_idx > 0 ? `${base_save_name}_f${curr_frame_idx}` : base_save_name;
      const image_save_name = `${model_save_name}_image`;
      const depth_save_name = `${model_save_name}_depth_24bit`;
      const mask_save_name = `${model_save_name}_mask`;
      const is_metric_depth = SOURCEINFO.is_metric_depth;
      const image_save_ext = CTRLS.save_model_image_as_jpeg ? "jpeg" : "png";
      const depth_save_ext = "png";

      // Get data for saving
      const uniform_data = GLDATA.read_current_uniform_data();
      const [image_data, depth_data] = TEXTUREDATA.read_current_texture_data();
      const [full_xy_list, full_face_list] = MESHDATA.read_current_mesh_data();
      const [is_valid_list, full_xyz_list, full_uv_list] = run_vertex_shader_cpu(
        full_xy_list, uniform_data, depth_data, is_metric_depth
      );

      // Filter out invalid (e.g. by masking) vertices and correspond faces
      const [v_xyz, v_uv, face_idx_list] = filter_mesh_vertices(
        is_valid_list, full_xyz_list, full_uv_list, full_face_list,
      );

      // Save mesh data in .glb format (default) or use .obj if enabled
      if (CTRLS.save_model_as_obj) {
        const obj_save_str = create_obj_string(v_xyz, v_uv, face_idx_list);
        save_obj_data(model_save_name, obj_save_str);
        save_image_data(image_save_name, image_data, image_save_ext);
      } else {
        const binary_data = await create_glb_binary(v_xyz, v_uv, face_idx_list, image_data, image_save_ext);
        save_glb_data(model_save_name, binary_data);
      }

      // Save depth/mask image data in 24bit format, if needed
      if (CTRLS.save_model_depth || CTRLS.save_model_mask) {
        const [d24_data, mask_data] = split_rgb_and_alpha(depth_data);
        if (CTRLS.save_model_depth) save_image_data(depth_save_name, d24_data, depth_save_ext);
        if (CTRLS.save_model_mask) save_image_data(mask_save_name, mask_data, depth_save_ext);
      }

      DOM.blocker.close();
    }, 100);
  });

  // Add basic render update listeners
  [
    fov_ctrl, tilt_ctrl, nplane_ctrl, zoff_ctrl,
    dmin_ctrl, dmax_ctrl,
    maskthresh_ctrl,
    pointsize_ctrl, ortho_toggle,
  ].forEach(elem => elem.add_listener(rerender));

  // Add re-mesh listeners
  [tri_toggle, density_ctrl, jitter_ctrl].forEach(elem => {
    elem.add_listener(() => {
      update_mesh();
      rerender();
    });
  });
  dispres_ctrl.add_listener(() => {
    DISPLAYINFO.res_scale = dispres_ctrl.value;
    update_main_canvas_sizing();
  });

  // Special callback for changes that require shader compilation
  [depth_toggle].forEach(elem => elem.add_listener(() => {
    update_gl_program();
    rerender();
  }));

  // Listener for play/pause behavior
  DOM.playpause_btn.addEventListener("click", () => {

    // Toggle play/pause state
    ANIMSTATE.is_playing = !ANIMSTATE.is_playing;

    // Toggle play/pause icons
    if (ANIMSTATE.is_playing) {
      DOM.symbol_play.classList.add(GCSS.hidden);
      DOM.symbol_pause.classList.remove(GCSS.hidden);
    } else {
      DOM.symbol_play.classList.remove(GCSS.hidden);
      DOM.symbol_pause.classList.add(GCSS.hidden);
    }

    // If we started playing, begin animation requests. Otherwise stop existing animation
    if (ANIMSTATE.is_playing) {
      ANIMSTATE.idx = requestAnimationFrame(request_current_frame);
    } else {
      cancelAnimationFrame(ANIMSTATE.idx);
      ANIMSTATE.idx = null;
    }
    return
  });

  // Listener for adjusting playback slider
  const playback_event_handler = new UIRateLimiter(DOM.playback_ctrl, 2);
  playback_event_handler.addEventListener("input", () => {
    if (ANIMSTATE.is_playing) {
      playpause_btn.click();
    }
    ANIMSTATE.idx = requestAnimationFrame(request_current_frame);
  });

  // Listeners for hiding/showing controls
  DOM.unhide_btn.addEventListener("click", () => DOM.hide_btn.click());
  DOM.hide_btn.addEventListener("click", () => {
    DOM.sidebar.classList.toggle(GCSS.hidden);
    DOM.unhide_btn.classList.toggle(GCSS.hidden);
  });

  // Drag-and-drop handler for uploading new image files
  DOM.canvas_3d.addEventListener("dragenter", evt => {
    evt.preventDefault();
    DOM.canvas_3d.classList.add(GCSS.drag_and_drop);
  });
  DOM.canvas_3d.addEventListener("dragleave", evt => {
    evt.preventDefault();
    DOM.canvas_3d.classList.remove(GCSS.drag_and_drop);
  });
  DOM.canvas_3d.addEventListener("dragover", evt => {
    evt.preventDefault();
  })
  DOM.canvas_3d.addEventListener("drop", async evt => {
    evt.preventDefault();

    // Sanity check. Make sure we got at least 1 file (and warn if we got more than 1)
    const uploaded_files = evt.dataTransfer.files;
    if (uploaded_files.length === 0) {
      console.warn("No files uploaded!")
      return;
    } else if (uploaded_files.length > 1) {
      console.warn("Only 1 file upload is allowed at a time!");
    }

    // Send image to server to use as new source for depth prediction
    const file = uploaded_files[0];
    const is_image_file = file.type.startsWith("image");
    if (is_image_file) {

      // Handle special case, where we ask user (one time) if uploaded 'mask' file is actually a mask
      // -> We default to treating all future 'mask' files the same way (i.e. always a mask or never a mask)
      const has_mask_in_name = file.name.toLowerCase().includes("mask");
      let is_mask_image = has_mask_in_name ? DEFAULT_IS_UPLOADED_MASK : false;
      if (is_mask_image && ASK_FOR_MASK_UPLOAD_CONFIRMATION) {
        is_mask_image = window.confirm("Found 'mask' in file name. Would you like to treat this as a mask?");
        DEFAULT_IS_UPLOADED_MASK = is_mask_image;
        ASK_FOR_MASK_UPLOAD_CONFIRMATION = false;
      }

      if (is_mask_image) {
        // Use image as a mask for depth data
        const [_, depth_wh] = TEXTUREDATA.get_wh();
        const mask_image_data = await parse_uploaded_image_data(file, depth_wh);
        TEXTUREDATA.update_mask(mask_image_data);
        rerender();

      } else {
        // Send image to server for depth prediction
        const post_headers = {"Content-Type": file.type, "X-filename": file.name};
        const buffer_data = await file.arrayBuffer();
        const resp = await fetch("/upload", {method: "POST", body: buffer_data, headers: post_headers})
        if (resp.ok && resp.status === 201) {
          initialize_page();
        }
      }


    } else {
      alert(`Only image files can be uploaded! Got: ${file.type}`);
    }

    // Clear drag-state indicator if needed
    DOM.canvas_3d.classList.remove(GCSS.drag_and_drop);

    return;
  })

  // Canvas resizer (shouldn't happen often!)
  window.addEventListener("resize", update_main_canvas_sizing);

  // Finalize display by asking for first frame!
  initialize_page();


  // -----------------------------------------------------------------------------------------------------------------
  // Keypress controls

  document.addEventListener("keydown", evt => {

    // Toggle image vs. depth coloring
    if (evt.code === "KeyV") {
      depth_toggle.toggle();
    }

    // Toggle triangle vs. point rendering
    if (evt.code === "KeyT") {
      tri_toggle.toggle();
    }

    // Switch ortho camera
    if (evt.code === "KeyO") {
      ortho_toggle.toggle();
    }

    // Toggle line rendering
    if (evt.code === "KeyL") {
      CTRLS.debug_line_render = !CTRLS.debug_line_render;
      update_mesh();
      rerender();
    }

    // Toggle masking settings
    if (evt.code === "KeyM") {
      const new_mask_thresh = maskthresh_ctrl.value;
      if (new_mask_thresh > 0) {
        LAST_MASK_THRESHOLD = new_mask_thresh;
        maskthresh_ctrl.set_value(0);
      } else {
        maskthresh_ctrl.set_value(LAST_MASK_THRESHOLD);
      }
    }

    // Hide controls
    if (evt.code === "KeyH") {
      // Toggle control hiding, but always hide 'show controls' button when using keys
      DOM.hide_btn.click();
      DOM.unhide_btn.classList.add(GCSS.hidden);
      if (DOM.hide_btn.checkVisibility()) {
        DOM.playback_container.classList.remove(GCSS.hidden)
      } else {
        DOM.playback_container.classList.add(GCSS.hidden);
      }
    }

    // Toggle frame saving (uses the ` key, aka tilde key ~)
    if (evt.code === "Backquote") {
      SAVECONFIG.enable = !SAVECONFIG.enable;
      if (SAVECONFIG.enable) {
        DOM.page.classList.add(GCSS.is_recording);
      } else {
        DOM.page.classList.remove(GCSS.is_recording);
      }
    }

    // Toggle playback with spacebar
    if (evt.code === "Space") {
      evt.preventDefault();

      if (SOURCEINFO.is_video_file || SOURCEINFO.is_webcam) {
        DOM.playpause_btn.click();
      }
      if (SOURCEINFO.is_video_file) {
        DOM.playback_ctrl.focus();
      }
    }

    // Adjust display resolution using +/- keys
    if (evt.code === "Minus" && !evt.ctrlKey) {
      dispres_ctrl.set_value(dispres_ctrl.value - 0.1);
    } else if (evt.code === "Equal" && !evt.ctrlKey) {
      dispres_ctrl.set_value(dispres_ctrl.value + 0.1);
    }

    // Adjust point sizing using square bracket keys [ & ]
    if (["BracketLeft", "BracketRight"].includes(evt.code)) {
      (evt.code == "BracketLeft") ? pointsize_ctrl.decrement() : pointsize_ctrl.increment();
      pointsize_ctrl.trigger();
    }

    // Snap camera with xyz keys
    if (["KeyX", "KeyY", "KeyZ"].includes(evt.code)) {
      const is_snap_x = (evt.code === "KeyX");
      const is_snap_y = (evt.code === "KeyY");
      const is_snap_z = (evt.code === "KeyZ");
      ORBITCAM.snap_to_axis(is_snap_x, is_snap_y, is_snap_z, invert = evt.shiftKey);
      rerender();
    }

    // Move camera as if in first-person with WASD or arrow keys
    if (["KeyW", "KeyS", "KeyA", "KeyD"].includes(evt.code)) {
      const scale = CTRLS.wasd_sensitivity * CTRLS.depth_limit * dmax_ctrl.value;
      const dx = scale * ((evt.code === "KeyA") - (evt.code === "KeyD"));
      const dz = scale * ((evt.code === "KeyW") - (evt.code === "KeyS"));
      ORBITCAM.translate(dx, 0, dz);
      rerender();
    }
  });

  // -----------------------------------------------------------------------------------------------------------------
  // Functions

  async function initialize_page() {

    /* Function used to get the page ready for display/playback on initial load */

    // Retrieve setup info from server
    const resp = await fetch("/get-source-info");
    const resp_json = await resp.json();
    console.log("Showing:", resp_json["source_name"]);
    console.log(resp_json);

    // Get image sizing info
    const {image_wh, depth_wh} = resp_json;

    // Grab info about video source
    SOURCEINFO.name = resp_json["source_name"];
    SOURCEINFO.total_frame_count = resp_json["total_frames"];
    SOURCEINFO.max_frame_idx = SOURCEINFO.total_frame_count - 1;
    SOURCEINFO.is_metric_depth = resp_json["is_metric_depth"];
    SOURCEINFO.is_static_image = resp_json["is_static_image"];
    SOURCEINFO.is_video_file = resp_json["is_video_file"];
    SOURCEINFO.is_webcam = resp_json["is_webcam"];
    const initial_frame_index = resp_json["frame_index"];
    
    // Get data encoding settings (for parsing images sent by the server)
    ENCODEINFO.rgb = resp_json["encode_type_rgb"];
    ENCODEINFO.depth = resp_json["encode_type_depth"];
    
    // Record texture sizing
    const [img_w, img_h] = image_wh;
    const [dep_w, dep_h] = depth_wh;
    IMAGEINFO.width = img_w;
    IMAGEINFO.height = img_h;
    IMAGEINFO.ar = img_w / img_h;
    DEPTHINFO.width = dep_w;
    DEPTHINFO.height = dep_h;
    DEPTHINFO.ar = dep_w / dep_h;

    // Set slider to appropriate range and initial frame
    DOM.playback_ctrl.min = 0;
    DOM.playback_ctrl.max = SOURCEINFO.max_frame_idx;
    DOM.playback_ctrl.value = initial_frame_index;

    // Change default control values for metric depth predictions
    if (SOURCEINFO.is_metric_depth) {
      nplane_ctrl.set_value(0);
      dmax_ctrl.set_value(0.20);
      dmin_ctrl.set_value(0);
    }

    // If we have a video source, show the play button and (if it's not a webcam) show the playback bar as well
    if (SOURCEINFO.is_video_file) {
      DOM.playback_container.classList.remove(GCSS.hidden);
      DOM.playpause_btn.classList.remove(GCSS.hidden);
      DOM.playback_ctrl.classList.remove(GCSS.hidden);
    } else if (SOURCEINFO.is_webcam) {
      DOM.playback_container.classList.remove(GCSS.hidden);
      DOM.playpause_btn.classList.remove(GCSS.hidden);
      if (!ANIMSTATE.is_playing) DOM.playpause_btn.click();
    } else {
      [DOM.playback_container, DOM.playpause_btn, DOM.playback_ctrl].forEach(elem => elem.classList.add(GCSS.hidden));
      if (ANIMSTATE.is_playing) DOM.playpause_btn.click();
    }

    // Update render data/display
    TEXTUREDATA.allocate(image_wh, depth_wh);
    update_main_canvas_sizing();
    update_mesh();
    update_gl_program();
    request_current_frame();

    return;
  }

  // ..................................................................................................................

  function rerender() {
    /* Helper used to handle re-renders for control updates */
    if (!ANIMSTATE.is_playing) {
      cancelAnimationFrame(ANIMSTATE.idx);
      ANIMSTATE.idx = requestAnimationFrame(render_3d);
    }
  }

  // ..................................................................................................................

  function update_gl_program() {

    /* Helper used to set (or swap) the current webgl program */

    // Connect texture & mesh data to program
    const gl_program = GLDATA.create_new_program(SOURCEINFO.is_metric_depth, depth_toggle.value);
    TEXTUREDATA.bind_gl_program(gl_program);
    MESHDATA.bind_gl_program(gl_program);

    return;
  }

  // ..................................................................................................................

  function update_main_canvas_sizing() {

    /* Function used to scale the display canvas (includes support for downscaling compared to display resolution) */

    DISPLAYINFO.width = DOM.canvas_3d.clientWidth;
    DISPLAYINFO.height = DOM.canvas_3d.clientHeight;
    DISPLAYINFO.ar = DISPLAYINFO.width / DISPLAYINFO.height;

    const [res_w, res_h] = [DISPLAYINFO.width, DISPLAYINFO.height].map(v => v * DISPLAYINFO.res_scale);
    DOM.canvas_3d.width = res_w;
    DOM.canvas_3d.height = res_h;
    DOM.canvas_3d.style.width = res_w;
    DOM.canvas_3d.style.height = res_h

    rerender();
  }

  // ..................................................................................................................

  function update_mesh() {

    /* Helper used to update mesh data based on UI settings */

    // Update drawing style if needed
    let draw_mode = (tri_toggle.value ? WebGL2RenderingContext.TRIANGLES : WebGL2RenderingContext.POINTS);
    if (CTRLS.debug_line_render) {
      draw_mode = WebGL2RenderingContext.LINES;
    }
    DISPLAYINFO.draw_mode = draw_mode;

    // Create new mesh
    const mesh_wh = [IMAGEINFO.width, IMAGEINFO.height];
    const num_faces_pct = density_ctrl.value;
    const vertex_jitter = jitter_ctrl.value;
    const target_num_faces = Math.pow(Math.min(1.0, num_faces_pct), 4) * CTRLS.max_faces;
    MESHDATA.update(mesh_wh, target_num_faces, vertex_jitter, draw_mode);
  }

  // ..................................................................................................................

  async function request_current_frame() {

    /*
    Function used to retrieve the frame given by the current playback bar position.
    Also advances the playback bar if a video is playing, so that repeat calls to
    this function will 'animate' the rendering
    */

    // Get image data and write to the GPU
    let curr_idx = parseInt(DOM.playback_ctrl.value);
    const [rgb_bmp, depth_bmp] = await fetch_images(curr_idx);
    TEXTUREDATA.update(rgb_bmp, depth_bmp);

    // Render new image data!
    render_3d();
    
    // Request the next frame for rendering, if needed
    if (ANIMSTATE.is_playing) {
      curr_idx = (curr_idx + 1) % SOURCEINFO.max_frame_idx;
      DOM.playback_ctrl.value = curr_idx;
      ANIMSTATE.idx = requestAnimationFrame(request_current_frame);
    }
    
    return;
  }

  // ..................................................................................................................

  async function fetch_images(frame_index) {
    
    /*
    Function used to request RGB & depth image data from the server
    - Expects server to provide a single binary 'blob' representing both images
    - Expects headers to indicate how large each image is in blob (for splitting)

    Returns:
      [rgb_bitmap, depth_bitmap] (as promises)
    */

    // Request images and read sizing info from header
    let resp;
    try {
      resp = await fetch(`frame/${frame_index}`);
    } catch {
      alert("Error requesting frame data! Server is down...?");
    }
    
    // Figure out data sizing info, so we can properly split binary array
    const rgb_img_size = parseInt(resp.headers.get(ENCODEINFO.size_header_rgb));
    const depth_img_size = parseInt(resp.headers.get(ENCODEINFO.size_header_depth));
    const video_idx =  parseInt(resp.headers.get(ENCODEINFO.header_frame_index));
    if (video_idx != frame_index) {
      console.log("DEBUG - VIDX DOES NOT MATCH FIDX", frame_index, video_idx);
      DOM.playback_ctrl.value = video_idx;
    }
    
    // Separate response (binary) data into two images
    const buffer_data = await resp.arrayBuffer();
    const raw_binary_array = new Uint8Array(buffer_data);
    const rgb_img_data = raw_binary_array.slice(0, rgb_img_size);
    const depth_img_data = raw_binary_array.slice(rgb_img_size, rgb_img_size + depth_img_size);

    return await Promise.all(
      [
        get_image_bitmap(rgb_img_data, ENCODEINFO.rgb),
        get_image_bitmap(depth_img_data, ENCODEINFO.depth),
      ]
    );
  }

  // ..................................................................................................................

  async function get_image_bitmap(binary_data, mime_type) {
    /* Helper used to make bitmap datatype needed for sending image data to GPU as a texture */
    return createImageBitmap(
      new Blob([binary_data],
      { type: mime_type }), {imageOrientation: "flipY", premultiplyAlpha: "none"},
    );
  }

  // ...................................................................................................................

  async function parse_uploaded_image_data(file_upload, target_wh=null) {

    /*
    Function which takes an uploaded image file (e.g. from  event.dataTransfer.files)
    and returns an ImageData instance, so that pixel data can be accessed. If a
    [width, height] value is given, then the image data will be resized accordingly.
    Returns: image_data (instance of ImageData)
    Note: This can give distorted results if the file has alpha channel data!
    */

    // Sanity check
    const is_image_file = file_upload.type.startsWith("image");
    console.assert(is_image_file, "Error! Cannot parse non-image data");

    // Some indirection, js is weird! Need this for drawing to be able to get to pixel data
    const image_bytes = await file_upload.arrayBuffer();
    const image_bitmap = await get_image_bitmap(image_bytes, file_upload.type);
    const image_wh = [image_bitmap.width, image_bitmap.height];

    // Create canvas for drawing image
    const [targ_width, targ_height] = target_wh === null ? image_wh : target_wh;
    const temp_canvas = document.createElement("canvas");
    temp_canvas.width = targ_width;
    temp_canvas.height = targ_height;

    // Draw to canvas so we can read out pixel data
    const temp_ctx = temp_canvas.getContext("2d");
    temp_ctx.drawImage(image_bitmap, 0, 0, targ_width, targ_height);
    const image_data = temp_ctx.getImageData(0, 0, targ_width, targ_height);

    // Clean up
    temp_canvas.remove();

    return image_data;
  }

  // ...................................................................................................................

  function split_rgb_and_alpha(image_data) {

    /*
    Helper used to split an RGBA ImageData instance into separate RGB and
    alpha ImageData	instances. The main reason to do this is to avoid
    issues caused by writing ImageData to a canvas, when there is alpha data,
    which causes a 'lossy' transformation of the RGB values due to use of
    pre-multiplied alpha.
    Returns: [rgb_image_data, alpha_image_data]
    */

    // Split rgb & alpha
    const pixel_array = image_data.data;
    const num_bytes = pixel_array.length;
    const rgb_pixels = new Uint8ClampedArray(num_bytes);
    const alpha_pixels = new Uint8ClampedArray(num_bytes);
    for(let i=0; i<num_bytes; i+=4) {

      // Read input image pixel values
      const red = pixel_array[i+0];
      const green = pixel_array[i+1];
      const blue = pixel_array[i+2];
      const alpha = pixel_array[i+3];

      // Write rgb-only values
      rgb_pixels[i+0] = red;
      rgb_pixels[i+1] = green;
      rgb_pixels[i+2] = blue;
      rgb_pixels[i+3] = 255;

      // Write alpha-only values (as grayscale image)
      alpha_pixels[i+0] = alpha;
      alpha_pixels[i+1] = alpha;
      alpha_pixels[i+2] = alpha;
      alpha_pixels[i+3] = 255;
    }

    const rgb_image_data = new ImageData(rgb_pixels, image_data.width, image_data.height);
    const alpha_image_data = new ImageData(alpha_pixels, image_data.width, image_data.height);

    return [rgb_image_data, alpha_image_data];
  }

  // .................................................................................................................

  function render_3d() {

    /* Main render function! Calling this re-renders the 3D view */

    // Figure out vertex position scaling factors to correct for aspect ratio
    const is_wide_img = IMAGEINFO.width > IMAGEINFO.height;
    const x_scale_factor = is_wide_img ? 1.0 : (IMAGEINFO.width / IMAGEINFO.height);
    const y_scale_factor = is_wide_img ? (IMAGEINFO.height / IMAGEINFO.width) : 1.0;
    const point_size = pointsize_ctrl.value * (CTRLS.scale_points_with_zoom ? 1.0 / ORBITCAM.distance : 0.5);

    // Read controls
    const tilt_rad = tilt_ctrl.value * DEG2RAD;
    const max_depth = dmax_ctrl.value * CTRLS.depth_limit;
    const min_depth = dmin_ctrl.value * max_depth;
    const half_fov_rad_value = fov_ctrl.value * 0.5 * DEG2RAD;
    const near_plane_dist = nplane_ctrl.value * min_depth;
    const use_ortho_camera = ortho_toggle.value;
    const use_depth_texture = depth_toggle.value;
    const mask_threshold = maskthresh_ctrl.value;

    // Figure out depth scaling factors to get 'true' depth. Assumes inverse relative depth:
    const view_depth_offset = min_depth + zoff_ctrl.value * (max_depth - min_depth);
    let depth_a_value, depth_b_value;
    if (SOURCEINFO.is_metric_depth) {
      // MetricDepth = A + B*depth_pred
      depth_a_value = min_depth;
      depth_b_value = max_depth - min_depth;
    } else {
      // TrueDepth = 1 / (A + B*inv_depth)
      depth_a_value = 1.0 / max_depth;
      depth_b_value = (1.0 / min_depth) - (1.0 / max_depth);
    }

    // Figure out view & projection matrix
    const tilt_matrix = MAT4.rotate_x(-tilt_rad);
    const view_fov_rad = CTRLS.view_fov * DEG2RAD;
    const view_matrix = ORBITCAM.get_world_to_view_mat4()
    const proj_matrix = ORBITCAM.get_view_to_clipspace_mat4(view_fov_rad, DISPLAYINFO.ar, use_ortho_camera);
    const view_proj_matrix = MAT4.multiply(tilt_matrix, MAT4.multiply(view_matrix, proj_matrix));

    // Clear the canvas
    const gl = CTX.gl;
    gl.viewport(0, 0, gl.drawingBufferWidth, gl.drawingBufferHeight);
    gl.clearColor(0, 0, 0, 0);
    gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);

    // Set uniforms
    const is_transpose_matrix = false;
    gl.uniform4f(GLDATA.uniloc.scaling_factors, x_scale_factor, y_scale_factor, near_plane_dist, point_size);
    gl.uniform4f(GLDATA.uniloc.camera_params, depth_a_value, depth_b_value, half_fov_rad_value, view_depth_offset);
    gl.uniformMatrix4fv(GLDATA.uniloc.matrix, is_transpose_matrix, view_proj_matrix);
    gl.uniform1f(GLDATA.uniloc.mask_threshold, mask_threshold);

    // Render out data!
    MESHDATA.draw_elements(DISPLAYINFO.draw_mode);

    // Save every N frames, if enabled!
    if (SAVECONFIG.enable) {
      if (SAVECONFIG.idx % SAVECONFIG.rate === 0) {
        SAVECONFIG.link_elem.download = `${String(SAVECONFIG.idx).padStart(6, "0")}.png`;
        SAVECONFIG.link_elem.href = DOM.canvas_3d.toDataURL();
        SAVECONFIG.link_elem.click();
      }
      SAVECONFIG.idx += 1;
    }
  }

</script>

</body>
</html>
